\chapter{Introduction}
Artificial Intelligence (AI) is omnipresent nowadays; not just in science fiction novels, films, and TV series, but also in our day-to-day lives. Think about techniques that we use (daily) like navigation, language processing (both in speech recognition and speech generation, but also in, for instance, the grammar and spelling check in word processors), and data analytics and usage.

It can therefore not be denied that AI is making the transfer from a pure scientific nature to an applied reality. It is thus important that Computer Engineers are aware of the current possibilities of AI and how to apply those techniques in their jobs.

This reader is the accompanying document for the course \textit{Applied Artificial Intelligence} (\textsc{tcti-vkaai-17}) from the University of Applied Sciences Utrecht. 
In this course, we take a short step back, and discuss what AI is, and how it originated. This is meant to be a background on the practical issues of AI and getting to know which AI can and which it cannot solve. This introduction into AI is presented in chapter \ref{ch:intro}.

The main focus of the course is then shifted to the topic of Neural Networks. Neural networks originated from the minds of Cognitive Psychologists as a model of how the human brain functions, but has been slowly but surely evolved over the years into one of the most promising areas of (applied) artificial intelligence. Many of the recent developments in AI (that made the news) have been build using techniques from neural networks; IBM Watson wins \textit{Jeopardy!} \cite{watson}, Google AlphaMind defeats world champion Go \cite{alphamind}.

But what exactly is a neural network? How does it function? What problems can you solve with it? How does it do that? In chapter \ref{ch:nn} we discuss the basics of neural networks, and their fundamental workings.

Neural networks, as many of the advances of AI in the recent years, benefit greatly from the increase in computing power that we have gained since their inception (about 60 years ago). CPUs nowadays can perform many more computations than CPUs back then, and can process much larger problems due to the vast increases in memory available. Recent developments into GPU processing have further increased this computational capacity. Though it has to be noted that the main benefit from GPU computation is on parallel computation, not for linear computations. In chapter \ref{ch:opencl} we show that the computations needed for training and using neural networks, largely, adhere to these parallel constraints for benefiting from GPU optimalisations. Moreover, we show how (simple) neural networks can be programmed using the GPU to gain that computational benefit.

Finally, training a neural network is a large factor in the (potential) realisation of applications using such techniques. There are many factors to be considered (topology, type, weights, $\ldots$). As these factors influence each other, it is hard to make decisions on the right combination(s), making it difficult to optimise your solution. Due to the vast number of possible combinations, trying and testing each combination is infeasible. However, using another AI technique, namely Evolutionary Computing, likely candidates of combinations that would perform well can be found rather easily (and, maybe more importantly, fast). Evolutionary computing is an algorithmic approach to optimalisation, largely based on ideas taken from Evolution Theory \cite{darwin}. In chapter \ref{ch:ea} we explain the basics of evolutionary algorithms and how to apply these to optimise the training of a neural network.
